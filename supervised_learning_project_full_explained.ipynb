{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b080c71",
   "metadata": {},
   "source": [
    "# Predicting Player Engagement Using Supervised Learning\n",
    "\n",
    "This notebook presents a complete supervised learning pipeline for predicting player engagement levels in an online gaming dataset. The target variable is **`EngagementLevel`**, which has three categories: `High`, `Medium`, and `Low`.\n",
    "\n",
    "We explore:\n",
    "- Preprocessing of mixed-type data\n",
    "- Training multiple machine learning models\n",
    "- Evaluating models using classification metrics\n",
    "- Selecting the best performing model\n",
    "- Discussion on overfitting, hyperparameters, and model quality\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8cef285-9962-4184-9df8-0b742fa9e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "#!pip install --upgrade scikit-learn\n",
    "\n",
    "# Download latest version\n",
    "#path = kagglehub.dataset_download(\"rabieelkharoua/predict-online-gaming-behavior-dataset\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7cba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab408b75",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5100c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>GameGenre</th>\n",
       "      <th>PlayTimeHours</th>\n",
       "      <th>InGamePurchases</th>\n",
       "      <th>GameDifficulty</th>\n",
       "      <th>SessionsPerWeek</th>\n",
       "      <th>AvgSessionDurationMinutes</th>\n",
       "      <th>PlayerLevel</th>\n",
       "      <th>AchievementsUnlocked</th>\n",
       "      <th>EngagementLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000</td>\n",
       "      <td>43</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>16.271119</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>79</td>\n",
       "      <td>25</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9001</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>USA</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>5.525961</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9002</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>USA</td>\n",
       "      <td>Sports</td>\n",
       "      <td>8.223755</td>\n",
       "      <td>0</td>\n",
       "      <td>Easy</td>\n",
       "      <td>16</td>\n",
       "      <td>142</td>\n",
       "      <td>35</td>\n",
       "      <td>41</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9003</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>USA</td>\n",
       "      <td>Action</td>\n",
       "      <td>5.265351</td>\n",
       "      <td>1</td>\n",
       "      <td>Easy</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9004</td>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Action</td>\n",
       "      <td>15.531945</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PlayerID  Age  Gender Location GameGenre  PlayTimeHours  InGamePurchases  \\\n",
       "0      9000   43    Male    Other  Strategy      16.271119                0   \n",
       "1      9001   29  Female      USA  Strategy       5.525961                0   \n",
       "2      9002   22  Female      USA    Sports       8.223755                0   \n",
       "3      9003   35    Male      USA    Action       5.265351                1   \n",
       "4      9004   33    Male   Europe    Action      15.531945                0   \n",
       "\n",
       "  GameDifficulty  SessionsPerWeek  AvgSessionDurationMinutes  PlayerLevel  \\\n",
       "0         Medium                6                        108           79   \n",
       "1         Medium                5                        144           11   \n",
       "2           Easy               16                        142           35   \n",
       "3           Easy                9                         85           57   \n",
       "4         Medium                2                        131           95   \n",
       "\n",
       "   AchievementsUnlocked EngagementLevel  \n",
       "0                    25          Medium  \n",
       "1                    10          Medium  \n",
       "2                    41            High  \n",
       "3                    47          Medium  \n",
       "4                    37          Medium  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('online_gaming_behavior_dataset.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ba7f5",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c1a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "df['EngagementLevel_encoded'] = le.fit_transform(df['EngagementLevel'])\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df = pd.get_dummies(df, columns=['Location', 'Gender', 'GameGenre', 'GameDifficulty'], drop_first=True)\n",
    "\n",
    "# Drop non-informative columns\n",
    "X = df.drop(['PlayerID', 'EngagementLevel', 'EngagementLevel_encoded', 'PlayerLevel','AchievementsUnlocked'], axis=1)\n",
    "y = df['EngagementLevel_encoded']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f4538-7d83-4cd9-b41e-ffbc874d2775",
   "metadata": {},
   "source": [
    "The original categorical lables of EngagementLevels is \"low\", \"medium\" and \"high\". Since these labels are not useful when training datasets we create EngagementLevel_encoded, this label transforms \"low\", \"medium\" and \"high\" into \"0\", \"1\" and \"2\" instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e6fa98",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ba7b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      2035\n",
      "           1       0.80      0.70      0.75      2093\n",
      "           2       0.80      0.88      0.84      3879\n",
      "\n",
      "    accuracy                           0.82      8007\n",
      "   macro avg       0.83      0.80      0.81      8007\n",
      "weighted avg       0.82      0.82      0.82      8007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b7f13",
   "metadata": {},
   "source": [
    "## Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c66fcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84      2035\n",
      "           1       0.87      0.78      0.82      2093\n",
      "           2       0.82      0.92      0.87      3879\n",
      "\n",
      "    accuracy                           0.85      8007\n",
      "   macro avg       0.87      0.83      0.85      8007\n",
      "weighted avg       0.86      0.85      0.85      8007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed66112",
   "metadata": {},
   "source": [
    "## Model 3: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8ff5112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.78      2035\n",
      "           1       0.73      0.59      0.65      2093\n",
      "           2       0.72      0.81      0.77      3879\n",
      "\n",
      "    accuracy                           0.74      8007\n",
      "   macro avg       0.75      0.72      0.73      8007\n",
      "weighted avg       0.74      0.74      0.74      8007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863357d",
   "metadata": {},
   "source": [
    "## Model Comparison & Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c27b53ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores:\n",
      "Logistic Regression: 0.8171027850695111\n",
      "Random Forest: 0.8512166900964486\n",
      "KNN: 0.7382354337544175\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Scores:\")\n",
    "print(\"Logistic Regression:\", f1_score(y_test, y_pred_lr, average='weighted'))\n",
    "print(\"Random Forest:\", f1_score(y_test, y_pred_rf, average='weighted'))\n",
    "print(\"KNN:\", f1_score(y_test, y_pred_knn, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fefb9",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "Based on the **F1 score**, which balances precision and recall, we can select the model with the best performance on the test data.\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "**Overfitting** occurs when a model performs very well on training data but poorly on test data. It usually happens when the model is too complex or memorizes training patterns.\n",
    "\n",
    "**How to spot overfitting:**\n",
    "- Large gap between training and validation scores\n",
    "- Extremely high accuracy on training data but low F1 on test\n",
    "\n",
    "Cross-validation and regularization can help mitigate overfitting.\n",
    "\n",
    "### Hyperparameters Used\n",
    "\n",
    "- **Random Forest**: `n_estimators=100`, `max_depth=10` (limits complexity)\n",
    "- **KNN**: `n_neighbors=5` (common default, controls model flexibility)\n",
    "- **Logistic Regression**: Used `max_iter=1000` to ensure convergence\n",
    "\n",
    "### Evaluation Metrics Explained\n",
    "\n",
    "- **Accuracy**: Proportion of correct predictions (but can be misleading with imbalanced classes)\n",
    "- **Precision**: Of the predicted positives, how many were truly positive\n",
    "- **Recall (Sensitivity)**: Of all actual positives, how many were correctly predicted\n",
    "- **F1 Score**: Harmonic mean of precision and recall â€” balances both\n",
    "\n",
    "F1 score is especially useful for multi-class problems where class imbalance may exist.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e6fcedc-7b2f-410f-8d21-cd56b0ae2915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# Train the Random Forest model on the dataset\n",
    "# --------------------------------------------\n",
    "# We use a RandomForestClassifier with a fixed random_state for reproducibility.\n",
    "# The model is trained using the preprocessed training data.\n",
    "# After training, we save both the model and the scaler to .pkl files.\n",
    "# These files are later loaded in our prototype application (predict_engagement.py)\n",
    "# to make predictions without having to retrain the model every time.\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model and the scaler to disk\n",
    "# These should be excluded from version control (e.g., .gitignore)\n",
    "joblib.dump(rf_model, 'engagement_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabcce3b-b2bd-4bbe-b557-f0dec34a1d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2feffc-a3ff-4f10-82cf-83db3117199a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
